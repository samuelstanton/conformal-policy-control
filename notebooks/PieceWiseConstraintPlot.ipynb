{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, beta, uniform\n",
    "import sys\n",
    "\n",
    "\n",
    "x_values = np.linspace(-8, 10, 500)  # For plotting the curve\n",
    "\n",
    "m0 = 0\n",
    "s0 = 2.5\n",
    "pdf0_values = norm.pdf(x_values, loc=m0, scale=s0)\n",
    "\n",
    "\n",
    "def pdf0(x):\n",
    "    return norm.pdf(x, loc=m0, scale=s0)\n",
    "\n",
    "\n",
    "m1 = 5\n",
    "s1 = 1\n",
    "pdf1_values = norm.pdf(x_values, loc=m1, scale=s1)\n",
    "\n",
    "\n",
    "def pdf1(x):\n",
    "    return norm.pdf(x, loc=m1, scale=s1)\n",
    "\n",
    "\n",
    "lik_ratios = pdf1_values / pdf0_values\n",
    "# beta_quantiles = np.linspace(0, 1, 5)\n",
    "beta_quantiles = [0, 1 / 3, 0.5, 0.7, 0.8, 0.9, 1]\n",
    "betas = [np.quantile(lik_ratios, q) for q in beta_quantiles]\n",
    "betas[-1] = np.inf\n",
    "\n",
    "betas = betas\n",
    "beta_quantiles = beta_quantiles\n",
    "\n",
    "n_target = 10000\n",
    "\n",
    "\n",
    "# print(f'betas : {betas}')\n",
    "\n",
    "for i, beta in enumerate(betas):\n",
    "    pdf1_constrained_values = np.where(\n",
    "        lik_ratios < beta, pdf1_values, beta * pdf0_values\n",
    "    )\n",
    "    x_constraint_solution_ = np.where(lik_ratios < beta, True, False)\n",
    "\n",
    "    if np.sum(x_constraint_solution_) == len(x_constraint_solution_):\n",
    "        ## If True everywhere:\n",
    "        idx_x_left = -1\n",
    "        idx_x_right = -1\n",
    "    else:\n",
    "        idx_x_left = np.argmin(x_constraint_solution_)\n",
    "\n",
    "        idx_x_right = (\n",
    "            x_constraint_solution_.size - np.argmin(x_constraint_solution_[::-1]) - 1\n",
    "        )\n",
    "        print(f\"l, r : {idx_x_left}, {idx_x_right}\")\n",
    "\n",
    "    x_constraint_solution = x_values[np.sum(x_constraint_solution_) - 1]\n",
    "    if i == len(betas) - 1:\n",
    "        x_constraint_solution = -4\n",
    "\n",
    "    # if (beta_quantiles[i] <= 0.7):\n",
    "    # norm_const_est\n",
    "    # weight_else = 0\n",
    "    norm_const_est_vals = []\n",
    "    if beta <= 0.7:\n",
    "        ## Rejection sampling from safe dist\n",
    "        # n_proposal = 10000\n",
    "        accepted_samples = []\n",
    "        # for j in range(n_proposal):\n",
    "        while len(accepted_samples) < n_target:\n",
    "            u = uniform.rvs()\n",
    "            safe_sample = norm.rvs(loc=m0, scale=s0)\n",
    "            # if (u < pdf1(safe_samples[j])/(beta * pdf0(safe_samples[j]))):\n",
    "            # print(pdf1(safe_sample))\n",
    "            scaled_ratio = pdf1(safe_sample) / (beta * pdf0(safe_sample))\n",
    "            if scaled_ratio < 1:\n",
    "                norm_const_est_vals.append(pdf1(safe_sample) / pdf0(safe_sample))\n",
    "                # norm_const_est_vals.append(pdf1(safe_sample))\n",
    "            else:\n",
    "                norm_const_est_vals.append(beta)\n",
    "            if u < scaled_ratio:\n",
    "                accepted_samples.append(safe_sample)\n",
    "            # else:\n",
    "            #     print(\"rejected\")\n",
    "            # print('accepted')\n",
    "        # print(f\"norm_const_est_vals : {weight_if}\")\n",
    "        # print(f\"norm_const_est_vals : {weight_else}\")\n",
    "        norm_const_est = np.mean(norm_const_est_vals)\n",
    "\n",
    "    else:\n",
    "        # Rejection sampling from unconst dist\n",
    "        # n_proposal = 10000\n",
    "        # unconstrained_samples = norm.rvs(loc=m1, scale=s1, size=n_proposal)\n",
    "        accepted_samples = []\n",
    "        # for j in range(n_proposal):\n",
    "        while len(accepted_samples) < n_target:\n",
    "            u = uniform.rvs()\n",
    "            unconstrained_sample = norm.rvs(loc=m1, scale=s1)\n",
    "            # if (u < pdf0(unconstrained_samples[j]) * beta / pdf1(unconstrained_samples[j])):\n",
    "            scaled_ratio = (\n",
    "                pdf0(unconstrained_sample) * beta / pdf1(unconstrained_sample)\n",
    "            )\n",
    "            # print(scaled_ratio)\n",
    "            if scaled_ratio >= 1:\n",
    "                norm_const_est_vals.append(1)\n",
    "            else:\n",
    "                norm_const_est_vals.append(\n",
    "                    np.clip(\n",
    "                        pdf0(unconstrained_sample) * beta / pdf1(unconstrained_sample),\n",
    "                        a_min=None,\n",
    "                        a_max=99999999,\n",
    "                    )\n",
    "                )\n",
    "                # norm_const_est_vals.append(beta)\n",
    "\n",
    "            if u < scaled_ratio:\n",
    "                accepted_samples.append(unconstrained_sample)\n",
    "                # print('accepted')\n",
    "            # else:\n",
    "            #     print(\"rejected\")\n",
    "\n",
    "        norm_const_est = np.mean(norm_const_est_vals)\n",
    "    # if (len(norm_const_est_vals) > 0):\n",
    "    #     # print(norm_const_est_vals)\n",
    "    #     norm_const_est = np.mean(norm_const_est_vals)\n",
    "    # else:\n",
    "    #     norm_const_est = 1\n",
    "\n",
    "    # print(f'pdf1_constrained_values : {pdf1_constrained_values}')\n",
    "    # pdf1_constrained_values_normalized = pdf1_constrained_values\n",
    "    norm_const = (\n",
    "        np.sum(pdf1_constrained_values)\n",
    "        * (np.max(x_values) - np.min(x_values))\n",
    "        / len(x_values)\n",
    "    )\n",
    "    print(f\"norm_const : {norm_const}\")\n",
    "    # pdf1_constrained_values_normalized = pdf1_constrained_values / norm_const\n",
    "    pdf1_constrained_values_normalized = pdf1_constrained_values / norm_const_est\n",
    "    print(f\"norm_const_est : {norm_const_est}\")\n",
    "    # print(pdf1_constrained_values)\n",
    "\n",
    "    print(f\"beta : {beta}\")\n",
    "\n",
    "    if beta < max(betas):\n",
    "        plt.axvspan(\n",
    "            xmin=x_values[idx_x_left], xmax=x_values[idx_x_right], alpha=0.1, color=\"C2\"\n",
    "        )\n",
    "\n",
    "    plt.hist(np.array(accepted_samples), bins=100, density=True, alpha=0.5)\n",
    "\n",
    "    plt.plot(\n",
    "        x_values,\n",
    "        pdf0_values,\n",
    "        label=\"Safe Policy\",\n",
    "        color=\"C2\",\n",
    "        linestyle=\":\",\n",
    "        alpha=0.75,\n",
    "        linewidth=4,\n",
    "    )\n",
    "    plt.plot(\n",
    "        x_values,\n",
    "        pdf1_values,\n",
    "        label=\"Unconstrained Policy\",\n",
    "        color=\"C3\",\n",
    "        linestyle=\":\",\n",
    "        alpha=0.75,\n",
    "        linewidth=4,\n",
    "    )\n",
    "    plt.plot(\n",
    "        x_values,\n",
    "        pdf1_constrained_values_normalized,\n",
    "        label=\"Constrained Policy\",\n",
    "        color=\"C0\",\n",
    "        alpha=0.75,\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    if beta == np.inf:\n",
    "        plt.title(\n",
    "            rf\"Unconstrained Policy (Q($\\beta$) = {beta_quantiles[i]})\", fontsize=16\n",
    "        )\n",
    "    elif beta == min(betas):\n",
    "        plt.title(\n",
    "            rf\"Fully Constrained Policy (Q($\\beta$) = {beta_quantiles[i]})\", fontsize=16\n",
    "        )\n",
    "    else:\n",
    "        plt.title(\n",
    "            rf\"Partially Constrained Policy (Q($\\beta$) = {beta_quantiles[i]})\",\n",
    "            fontsize=16,\n",
    "        )\n",
    "\n",
    "    print(x_constraint_solution)\n",
    "    # plt.axvline(x=x_constraint_solution, color='black', linestyle=':', label=r'x s.t. p_t(x) / p_{safe} == $\\lambda$')\n",
    "    if i == len(betas) - 1:\n",
    "        plt.legend(loc=[0, 1.1], ncols=4, fontsize=12)\n",
    "    plt.xlabel(\"X\", fontsize=16)\n",
    "    plt.ylabel(\"Density\", fontsize=16)\n",
    "    plt.savefig(f\"./constrained_ex_beta{beta}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = norm.rvs(loc=m0, scale=s0, size=10)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n",
    "[*a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.float_info.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\n",
    "    \"/data/bucket/prinstea/llome/parent_output_20250901_temp1/smaller_pythia/smaller_pythia_sft_init_r0/gens_init_likelihood_100sample_2iter.jsonl\",\n",
    "    lines=True,\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-training initialization:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "for i in range(0, 5):\n",
    "    # data = pd.read_json(f'/data/bucket/prinstea/llome/parent_output_20250901_temp1/smaller_pythia/smaller_pythia_sft_init_r{i}/gens_init_likelihood_100sample_2iter.jsonl', lines = True)\n",
    "    data = pd.read_json(\n",
    "        f\"/data/bucket/prinstea/llome/parent_output_20250901_temp1/smaller_pythia/smaller_pythia_sft_init_r{i}/gens_init_likelihood_100sample_2iter_temp1.0_10seqs.jsonl\",\n",
    "        lines=True,\n",
    "    )\n",
    "    # num_inf = len(data[data['score']==np.inf])\n",
    "    num_infeasible = len(data[data[\"score\"].isna()]) + len(\n",
    "        data[data[\"score\"] == np.inf]\n",
    "    )\n",
    "    num_in_training = len(data[data[\"in_dataset\"]])\n",
    "\n",
    "    n = len(data)\n",
    "    print(f\"r{i}, n : {n}, frac infeasible  : {num_infeasible / n}\")\n",
    "    print(f\"r{i}, n : {n}, frac in training : {num_in_training / n} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\"col1\": range(1), \"col2\": [f\"val_{i}\" for i in range(1)]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set a random_state for reproducibility\n",
    "# This ensures that the same random split is generated every time the code is run\n",
    "random_seed = 42\n",
    "\n",
    "# Define the fraction for the first part (e.g., 80% for training)\n",
    "train_frac = 0.500001\n",
    "\n",
    "# Create the training set by sampling the specified fraction\n",
    "train_df = df.sample(frac=train_frac, random_state=random_seed)\n",
    "\n",
    "# Create the testing set by dropping the rows that are in the training set\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "print(\"Training DataFrame shape:\", train_df.shape)\n",
    "print(\"Testing DataFrame shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json('/data/bucket/prinstea/llome/parent_output/smaller_pythia/smaller_pythia_sft_r6/gens_likelihood_1sample_10iter_temp1.0_10seqs.jsonl', lines=True)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Extrapolation:\n",
    "for i in range(25):\n",
    "    # data = pd.read_json(f'/data/bucket/prinstea/llome/parent_output_20250901_temp1/smaller_pythia/smaller_pythia_sft_r{i}_20250901/gens_likelihood_10sample_10iter.jsonl', lines = True)\n",
    "    # data = pd.read_json(f'/data/bucket/prinstea/llome/parent_output_20250904_moreSFT_100s/smaller_pythia/smaller_pythia_sft_r{i}/gens_likelihood_100sample_1iter.jsonl', lines=True)\n",
    "    # data = pd.read_json(f'/data/bucket/prinstea/llome/parent_output_20250904_moreSFT_100s/smaller_pythia/smaller_pythia_sft_r{i}/gens_likelihood_25sample_1iter.jsonl', lines=True)\n",
    "    data = pd.read_json(\n",
    "        f\"/data/bucket/prinstea/llome/parent_output_20250904_moreSFT_10s/smaller_pythia/smaller_pythia_sft_r{i}/gens_likelihood_10sample_1iter.jsonl\",\n",
    "        lines=True,\n",
    "    )\n",
    "\n",
    "    # num_inf = len(data[data['score']==np.inf])\n",
    "    num_infeasible = len(data[data[\"score\"].isna()]) + len(\n",
    "        data[data[\"score\"] == np.inf]\n",
    "    )\n",
    "    num_in_training = len(data[data[\"in_dataset\"]])\n",
    "    # display(data.iloc[0:2,:])\n",
    "\n",
    "    n = len(data)\n",
    "    print(f\"r{i}, n : {n}, frac infeasible  : {num_infeasible / n}\")\n",
    "    print(f\"r{i}, n : {n}, frac in training : {num_in_training / n} \\n\")\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json('/data/bucket/prinstea/llome/parent_output/smaller_pythia/smaller_pythia_gpt/gens_init_likelihood_1000sample_10iter.jsonl', lines=True)\n",
    "# data = pd.read_json('/data/bucket/prinstea/llome/parent_output/smaller_pythia/smaller_pythia_gpt/gens_init_likelihood_1000sample_10iter_temp1.0_10seqs.jsonl', lines=True)\n",
    "# data = pd.read_json('/data/bucket/prinstea/llome/parent_output/smaller_pythia/gpt_unif_dense_neighborhood_pairs_xthres0.25_maxinfs0.1_30nn.jsonl', lines=True)\n",
    "# data\n",
    "data = pd.read_json(\n",
    "    \"/data/bucket/prinstea/llome/parent_output/smaller_pythia/smaller_pythia_sft_r1/gens_likelihood_100sample_10iter_temp1.0_10seqs.jsonl\",\n",
    "    lines=True,\n",
    ")\n",
    "# num_inf = len(data[data['score'].isna()]) + len(data[data['score']==np.inf])\n",
    "\n",
    "n = len(data)\n",
    "print(n)\n",
    "# print(f'r{i}, frac infeasible : {num_inf/n}')\n",
    "# data[\"in_dataset\"].sum()\n",
    "print(f\"Frac particles in training data : {len(data[data['in_dataset']]) / n}\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array(\n",
    "    [\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.9999757,\n",
    "        0.00268334,\n",
    "        0.9996437,\n",
    "        0.9984262,\n",
    "        0.9999994,\n",
    "        0.96831906,\n",
    "        0.9999993,\n",
    "        0.9276532,\n",
    "        0.9999999,\n",
    "        0.9457009,\n",
    "        1.0,\n",
    "        0.9989404,\n",
    "        1.0,\n",
    "        0.7990209,\n",
    "        1.0,\n",
    "        0.9945381,\n",
    "        0.99999654,\n",
    "        0.9836394,\n",
    "        1.0,\n",
    "        0.99783605,\n",
    "        1.0,\n",
    "        0.939762,\n",
    "        0.99999964,\n",
    "        0.999624,\n",
    "        1.0,\n",
    "        0.9961732,\n",
    "        1.0,\n",
    "        0.9590705,\n",
    "        1.0,\n",
    "        0.9468553,\n",
    "        0.99999976,\n",
    "        0.99964845,\n",
    "        0.99999964,\n",
    "        0.9756631,\n",
    "        0.9999999,\n",
    "        0.9997564,\n",
    "        1.0,\n",
    "        0.9998136,\n",
    "        0.99999976,\n",
    "        0.9795368,\n",
    "        0.99999845,\n",
    "        0.8060646,\n",
    "        0.99999905,\n",
    "        0.99828523,\n",
    "        0.999997,\n",
    "        0.9507775,\n",
    "        0.99999905,\n",
    "        0.9964759,\n",
    "        1.0,\n",
    "        0.98720807,\n",
    "        0.99999976,\n",
    "        0.9977544,\n",
    "        0.9998641,\n",
    "        0.9933022,\n",
    "        1.0,\n",
    "        0.49467334,\n",
    "        0.99999595,\n",
    "        0.8103291,\n",
    "        0.9999355,\n",
    "        0.9646651,\n",
    "        0.9999999,\n",
    "        0.99300814,\n",
    "        0.9999968,\n",
    "        0.82099724,\n",
    "        0.9999244,\n",
    "    ]\n",
    ")\n",
    "\n",
    "b = np.array(\n",
    "    [\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.99997985,\n",
    "        0.00346163,\n",
    "        0.9996593,\n",
    "        0.99715245,\n",
    "        0.9999993,\n",
    "        0.97442675,\n",
    "        0.99999917,\n",
    "        0.9453344,\n",
    "        0.9999999,\n",
    "        0.9257733,\n",
    "        1.0,\n",
    "        0.9991731,\n",
    "        1.0,\n",
    "        0.8534383,\n",
    "        1.0,\n",
    "        0.98922884,\n",
    "        0.99999654,\n",
    "        0.9874391,\n",
    "        1.0,\n",
    "        0.9980338,\n",
    "        1.0,\n",
    "        0.94244903,\n",
    "        0.9999999,\n",
    "        0.9993235,\n",
    "        1.0,\n",
    "        0.99135756,\n",
    "        1.0,\n",
    "        0.95656496,\n",
    "        1.0,\n",
    "        0.9656669,\n",
    "        0.9999999,\n",
    "        0.99915934,\n",
    "        0.9999994,\n",
    "        0.9750972,\n",
    "        0.9999999,\n",
    "        0.9995208,\n",
    "        1.0,\n",
    "        0.99948394,\n",
    "        0.9999987,\n",
    "        0.965408,\n",
    "        0.9999962,\n",
    "        0.8454996,\n",
    "        0.99999905,\n",
    "        0.9985127,\n",
    "        0.99999774,\n",
    "        0.9480506,\n",
    "        0.99999833,\n",
    "        0.98997724,\n",
    "        1.0,\n",
    "        0.9446316,\n",
    "        0.9999999,\n",
    "        0.9941362,\n",
    "        0.9999126,\n",
    "        0.9825868,\n",
    "        1.0,\n",
    "        0.60311216,\n",
    "        0.9999974,\n",
    "        0.90260494,\n",
    "        0.9999864,\n",
    "        0.9594176,\n",
    "        1.0,\n",
    "        0.9928461,\n",
    "        0.9999989,\n",
    "        0.78914386,\n",
    "        0.99979085,\n",
    "    ]\n",
    ")\n",
    "\n",
    "np.where((a == 0) & (b > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "generated_suffix = torch.empty((1, 0))\n",
    "generated_suffix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def func(a: List[str]):\n",
    "    return a\n",
    "\n",
    "\n",
    "a = [\"a\", \"b\"]\n",
    "func(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fp_list_str = \"\\\\[\"\n",
    "data_fp_list_str += \"asdf\"\n",
    "data_fp_list_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conformal-mfcs",
   "language": "python",
   "name": "conformal-mfcs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

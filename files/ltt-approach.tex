\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[numbers]{natbib}
\usepackage{authblk, caption, floatrow}
\usepackage{palatino}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{bm, bbm}
\usepackage[pdftex]{graphicx}
\usepackage{xcolor,xparse}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{makecell}
% \usepackage[ruled,vlined]{algorithm2e}
\usepackage{algpseudocode, algorithm}  % or above line
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{ifthen}
\mathtoolsset{showonlyrefs=false}

\title{LTT approach?}
\author{}
\date{}

\begin{document}

\maketitle

For simplicity, consider a single step in time.
Let $\pi_{\theta_0}$ denote the safe policy, where $\mathbb{E}_{X \sim\pi_{\theta_0}} [L(X)]\leq \alpha$, and let $\tilde{\pi}_{\theta_t}$ denote the optimistic policy.
At time $t$, we have calibration data, $\mathcal{D}_\text{cal} = \{(X_i, L(X_i))\}_{i = 1}^n$, where $X_i$ are sampled i.i.d. from some policy $\pi_{\theta_t}$.

Consider any family of distributions indexed by positive $\beta$ that interpolates between $\pi_{\theta_0}$ and $\tilde{\pi}_{\theta_t}$, \mbox{$\{\pi^\beta_{\theta_t}: \beta > 0\}$}.
We describe a procedure that, given any error level $\delta \in [0, 1]$, selects $\beta_t = \hat{\beta}_\delta(\mathcal{D}_\text{cal})$ as a function of the calibration data, such that
\begin{align}
\label{eq:guarantee}
    \mathbb{P}_{\mathcal{D}_\text{cal}}(\mathbb{E}_{\pi^{\beta_t}_{\theta_t}}[L(X)] \leq \alpha) \geq 1 - \delta.
\end{align}
Let $H_\beta: \mathbb{E}_{\pi^{\beta}_{\theta_t}}[L(X)] > \alpha$ denote the null hypothesis for the candidate distribution indexed by $\beta$.
We can compute a p-value, $p_\beta$, testing against this null hypothesis by using CLT to characterize the asymptotic distribution of the following importance-weighted sample mean that we can compute, which has expectation $\mathbb{E}_{\pi^{\beta}_{\theta_t}}[L(X)]$:
\begin{align}
\label{eq:sample-mean}
    \frac{1}{n}\sum_{i = 1}^n \frac{\pi^{\beta}_{\theta_t}(X)}{\pi_{\theta_t}(X)} L(X_i).
\end{align}
For each $\beta$, we have that $\mathbb{P}_{H_{\beta}}(p_\beta \leq \delta) \leq \delta$ by the definition of a p-value.
If we compute $p_\beta$ for a fixed ordering of values of $\beta$, and set $\beta_t$ to be the first value of that is not rejected ($p_\beta > \delta$), we have that $\mathbb{P}_{\mathcal{D}_\text{cal}}(H_{\beta_t} \text{ is true}) \leq \delta$ since fixed-sequence testing gives family-wise error rate control.
The randomness is over the calibration data, since $\beta_t$ is a function of the calibration data.

If the calibration data are not i.i.d, we can introduce appropriate weighting in Eq.~\eqref{eq:sample-mean} to retain the guarantee in Eq.~\eqref{eq:guarantee}.


\end{document}
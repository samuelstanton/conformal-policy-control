{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Jupyter notebook for plotting Figure 3 and supplementary Appendix E figures in \"Conformal Validity Guarnatees Exist for Any Data Distribution\" (ICML 2024)\n",
    "\n",
    "Notebook by Drew Prinster (drew@cs.jhu.edu)\n",
    "\n",
    "Last updated June 28th, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import decomposition\n",
    "from scipy.stats import logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "\n",
    "# Load the ARFF file\n",
    "# The loadarff function returns a tuple: (data as a record array, metadata)\n",
    "robot_arm_data_, meta_ = arff.loadarff(\n",
    "    os.getcwd().removesuffix(\"bash_scripts\")\n",
    "    + \"/datasets/robot_arm/dataset_2175_kin8nm.arff\"\n",
    ")\n",
    "robot_arm_data = pd.DataFrame(robot_arm_data_)\n",
    "X_robot_arm = robot_arm_data.iloc[:, :-1].to_numpy()\n",
    "Y_robot_arm = robot_arm_data.iloc[:, -1].to_numpy()\n",
    "n_robot_arm = len(robot_arm_data)\n",
    "# Convert the record array into a pandas DataFrame\n",
    "n_robot_arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"robot_arm\"\n",
    "pc_alpha = 0.2\n",
    "heteroscedastic = \"N\"\n",
    "noise_magnitude = 0.05\n",
    "seed = 2\n",
    "n_val = 100\n",
    "n_initial_all = 200\n",
    "replacement = True\n",
    "n_train_proper_initial = 100\n",
    "initial_sampling_bias = 8.0\n",
    "\n",
    "print(f\"pc_alpha : {pc_alpha}\")\n",
    "\n",
    "\n",
    "def compute_errors_for_measurements(X_vals, Y_vals):\n",
    "    \"\"\"\n",
    "    Given indices of sequences, return noisy measurements (using estimated measurement noise SD).\n",
    "\n",
    "    :param Y_vals: Y values\n",
    "    :param muh: predictor function whose predictions are used for estimating measurement noise magnitude\n",
    "    :param seed: int, random seed\n",
    "    :return: numpy array of noisy measurements corresponding to provided sequence indices\n",
    "    \"\"\"\n",
    "\n",
    "    krr = KernelRidge(alpha=1.0)\n",
    "    krr.fit(X_vals, Y_vals)\n",
    "    return abs(Y_vals - krr.predict(X_vals))\n",
    "\n",
    "\n",
    "if dataset == \"airfoil\":\n",
    "    airfoil = pd.read_csv(\n",
    "        os.getcwd().removesuffix(\"bash_scripts\") + \"/datasets/airfoil/airfoil.txt\",\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "    )\n",
    "    airfoil.columns = [\"Frequency\", \"Angle\", \"Chord\", \"Velocity\", \"Suction\", \"Sound\"]\n",
    "    X_airfoil = airfoil.iloc[:, 0:5].values\n",
    "    X_airfoil[:, 0] = np.log(X_airfoil[:, 0])\n",
    "    X_airfoil[:, 4] = np.log(X_airfoil[:, 4])\n",
    "    Y_airfoil = airfoil.iloc[:, 5].values\n",
    "    n_airfoil = len(Y_airfoil)\n",
    "    # errs_airfoil = compute_errors_for_measurements(X_airfoil, Y_airfoil)\n",
    "\n",
    "\n",
    "elif dataset == \"wine\":\n",
    "    winequality_red = pd.read_csv(\n",
    "        os.getcwd().removesuffix(\"bash_scripts\") + \"/datasets/wine/winequality-red.csv\",\n",
    "        sep=\";\",\n",
    "    )\n",
    "    X_wine = winequality_red.iloc[:, 0:11].values\n",
    "    Y_wine = winequality_red.iloc[:, 11].values\n",
    "    n_wine = len(Y_wine)\n",
    "    # errs_wine = compute_errors_for_measurements(X_wine, Y_wine)\n",
    "\n",
    "    print(\"X_wine shape : \", X_wine.shape)\n",
    "\n",
    "\n",
    "elif dataset == \"communities\":\n",
    "    # UCI Communities and Crime Data Set\n",
    "    # download from:\n",
    "    # http://archive.ics.uci.edu/ml/datasets/communities+and+crime\n",
    "    communities_data = np.loadtxt(\n",
    "        os.getcwd().removesuffix(\"bash_scripts\")\n",
    "        + \"/datasets/communities/communities.data\",\n",
    "        delimiter=\",\",\n",
    "        dtype=str,\n",
    "    )\n",
    "    # remove categorical predictors\n",
    "    communities_data = np.delete(communities_data, np.arange(5), 1)\n",
    "    # remove predictors with missing values\n",
    "    communities_data = np.delete(\n",
    "        communities_data,\n",
    "        np.argwhere((communities_data == \"?\").sum(0) > 0).reshape(-1),\n",
    "        1,\n",
    "    )\n",
    "    communities_data = communities_data.astype(float)\n",
    "    X_communities = communities_data[:, :-1]  ## Reducing size for 20250627\n",
    "    Y_communities = communities_data[:, -1]  ## Reducing size for 20250627\n",
    "    n_communities = len(Y_communities)\n",
    "    # errs_communities = compute_errors_for_measurements(X_communities, Y_communities)\n",
    "    print(\"X_communities shape : \", X_communities.shape)\n",
    "\n",
    "elif dataset == \"meps\":\n",
    "    meps_data = np.loadtxt(\n",
    "        os.getcwd().removesuffix(\"bash_scripts\") + \"/datasets/meps/meps_data.txt\"\n",
    "    )\n",
    "    X_meps = meps_data[:, :-1]\n",
    "    Y_meps = meps_data[:, -1]\n",
    "    n_meps = len(Y_meps)\n",
    "    # errs_meps = compute_errors_for_measurements(X_meps, Y_meps)\n",
    "    print(\"X_meps shape : \", X_meps.shape)\n",
    "\n",
    "elif dataset == \"blog\":\n",
    "    blog_data = np.loadtxt(\n",
    "        os.getcwd().removesuffix(\"bash_scripts\") + \"/datasets/blog/blogData_train.csv\",\n",
    "        delimiter=\",\",\n",
    "    )\n",
    "    X_blog = blog_data[:, :-1]\n",
    "    Y_blog = np.log(1 + blog_data[:, -1])\n",
    "    n_blog = len(Y_blog)\n",
    "    # errs_blog = compute_errors_for_measurements(X_blog, Y_blog)\n",
    "\n",
    "\n",
    "elif dataset == \"robot_arm\":\n",
    "    robot_arm_data_, meta_ = arff.loadarff(\n",
    "        os.getcwd().removesuffix(\"bash_scripts\")\n",
    "        + \"/datasets/robot_arm/dataset_2175_kin8nm.arff\"\n",
    "    )\n",
    "    robot_arm_data = pd.DataFrame(robot_arm_data_)\n",
    "    X_robot_arm = robot_arm_data.iloc[:, :-1].to_numpy()\n",
    "    Y_robot_arm = robot_arm_data.iloc[:, -1].to_numpy()\n",
    "    n_robot_arm = len(robot_arm_data)\n",
    "\n",
    "display(X_communities)\n",
    "\n",
    "# plt.hist(Y_meps, bins=30)\n",
    "\n",
    "\n",
    "def get_PCA(x):\n",
    "    pca = decomposition.PCA(n_components=1)\n",
    "    pca.fit(x)\n",
    "    x_pca = pca.transform(x)\n",
    "    return x_pca, pca\n",
    "\n",
    "\n",
    "def get_rel_ranks(arr):\n",
    "    order = arr.argsort()\n",
    "    return order.argsort() / len(arr)\n",
    "\n",
    "\n",
    "def noisy_measurements(\n",
    "    idx_y, Y_vals_all, errs=None, noise_magnitude=0.05, seed: int = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Given indices of sequences, return noisy measurements (using estimated measurement noise SD).\n",
    "\n",
    "    :param idx_y: indices for y values\n",
    "    :param muh: predictor function whose predictions are used for estimating measurement noise magnitude\n",
    "    :param seed: int, random seed\n",
    "    :return: numpy array of noisy measurements corresponding to provided sequence indices\n",
    "    \"\"\"\n",
    "    #     np.random.seed(seed)\n",
    "    if errs is not None:\n",
    "        noisy_n = np.array(\n",
    "            [\n",
    "                np.random.normal(loc=Y_vals_all[i], scale=noise_magnitude * errs[i])\n",
    "                for i in idx_y\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        noisy_n = np.array(\n",
    "            [np.random.normal(loc=Y_vals_all[i], scale=noise_magnitude) for i in idx_y]\n",
    "        )\n",
    "    # enforce non-negative measurement since enrichment scores are always non-negative\n",
    "    return noisy_n\n",
    "\n",
    "\n",
    "X_all = eval(\"X_\" + dataset)\n",
    "all_inds = np.arange(eval(\"n_\" + dataset))\n",
    "\n",
    "X_all_pca_, pca_all_fitted = get_PCA(X_all)\n",
    "print(\"finished pca\")\n",
    "X_all_pca = X_all_pca_.flatten()\n",
    "X_all_pca_minmax = (X_all_pca - min(X_all_pca)) / (max(X_all_pca) - min(X_all_pca))\n",
    "# X_all_pca_rel_ranks = get_rel_ranks(X_all_pca)\n",
    "X_all_pca_exp = np.exp(X_all_pca_minmax * initial_sampling_bias)\n",
    "# print(f'divide sampling bias by : {100}')\n",
    "\n",
    "\n",
    "X_all_pca_exp_rel_ranks = get_rel_ranks(X_all_pca_exp)\n",
    "X_all_pca_exp_rel_ranks_logistic = logistic.cdf(\n",
    "    X_all_pca_exp_rel_ranks, loc=min(pc_alpha * 2.5, 0.98), scale=0.1\n",
    ")  # loc=0.55, scale=0.1)\n",
    "Feasible_all = np.random.binomial(n=1, p=X_all_pca_exp_rel_ranks_logistic)\n",
    "# plt.scatter(X_all_pca_exp_rel_ranks, X_all_pca_exp_rel_ranks_logistic)\n",
    "# plt.show()\n",
    "# plt.hist(Feasible_all, bins=20)\n",
    "print(f\"population average risk : {1 - np.mean(Feasible_all)}\")\n",
    "\n",
    "if heteroscedastic == \"Y\":\n",
    "    Y_all = noisy_measurements(\n",
    "        all_inds, eval(\"Y_\" + dataset), eval(\"errs_\" + dataset), noise_magnitude, seed\n",
    "    )\n",
    "else:\n",
    "    Y_all = noisy_measurements(\n",
    "        all_inds, eval(\"Y_\" + dataset), None, noise_magnitude, seed\n",
    "    )\n",
    "\n",
    "## Note: Validation set won't change, train and pool will\n",
    "np.random.seed(seed)\n",
    "val_inds = list(np.random.choice(eval(\"n_\" + dataset), n_val, replace=False))\n",
    "non_val_inds = np.setdiff1d(all_inds, val_inds)\n",
    "X_nonval = X_all[non_val_inds]\n",
    "\n",
    "\n",
    "## Bias initial sampling of training and calibration data to simulate selection bias in active learning\n",
    "# X_nonval_pca_, pca_fitted = get_PCA(X_nonval)\n",
    "# X_nonval_pca_, pca_fitted = get_PCA(X_all) ## (20250708: having this\n",
    "X_nonval_pca_ = pca_all_fitted.transform(X_nonval)\n",
    "X_nonval_pca = X_nonval_pca_.flatten()\n",
    "min_X_nonval_pca = min(X_nonval_pca)\n",
    "max_X_nonval_pca = max(X_nonval_pca)\n",
    "X_nonval_pca_minmax = (X_nonval_pca - min_X_nonval_pca) / (\n",
    "    max_X_nonval_pca - min_X_nonval_pca\n",
    ")\n",
    "X_nonval_pca_minmax_nonvals_exp = np.exp(X_nonval_pca_minmax * initial_sampling_bias)\n",
    "sum_X_nonval_pca_minmax_nonvals_exp = np.sum(X_nonval_pca_minmax_nonvals_exp)\n",
    "X_nonval_pca_minmax_nonvals_exp_normed = (\n",
    "    X_nonval_pca_minmax_nonvals_exp / sum_X_nonval_pca_minmax_nonvals_exp\n",
    ")\n",
    "\n",
    "# upper_q_exp_normed_val = np.quantile(X_nonval_pca_minmax_nonvals_exp_normed, 0.75)\n",
    "\n",
    "\n",
    "# def source_pdf(X, min_X_nonval_pca, max_X_nonval_pca, initial_sampling_bias, sum_X_nonval_pca_minmax_nonvals_exp, pca_fitted):\n",
    "def source_pdf(X):\n",
    "    X_pca = pca_all_fitted.transform(X)\n",
    "    X_pca_minmax = (X_pca - min_X_nonval_pca) / (max_X_nonval_pca - min_X_nonval_pca)\n",
    "    X_pca_minmax_exp = np.exp(X_pca_minmax * initial_sampling_bias)\n",
    "    X_pca_minmax_exp_normed = X_pca_minmax_exp / sum_X_nonval_pca_minmax_nonvals_exp\n",
    "    return X_pca_minmax_exp_normed.flatten()\n",
    "\n",
    "\n",
    "train_inds = list(\n",
    "    np.random.choice(\n",
    "        non_val_inds,\n",
    "        n_initial_all,\n",
    "        replace=replacement,\n",
    "        p=X_nonval_pca_minmax_nonvals_exp_normed,\n",
    "    )\n",
    ")\n",
    "\n",
    "## Pool inds are those not in training or validation data.\n",
    "pool_inds = list(\n",
    "    np.setdiff1d(np.setdiff1d(np.arange(eval(\"n_\" + dataset)), train_inds), val_inds)\n",
    ")\n",
    "\n",
    "## Create validation set (won't change)\n",
    "Xval = eval(\"X_\" + dataset)[val_inds]\n",
    "yval = Y_all[val_inds]\n",
    "Feasible_val = Feasible_all[val_inds]\n",
    "\n",
    "idx_split = list(np.random.permutation(train_inds))\n",
    "train_inds_split, cal_inds_split = (\n",
    "    list(idx_split[:n_train_proper_initial]),\n",
    "    list(idx_split[n_train_proper_initial:]),\n",
    ")\n",
    "\n",
    "## Note: Calibration set for split won't change\n",
    "Xtrain_split = eval(\"X_\" + dataset)[train_inds_split]\n",
    "ytrain_split = Y_all[train_inds_split]\n",
    "Feasible_train_split = Feasible_all[train_inds_split]\n",
    "\n",
    "# print(f'np.histogram(X_all_pca_exp_rel_ranks_logistic) : {np.histogram(X_all_pca_exp_rel_ranks_logistic)}')\n",
    "# print(f'np.mean(Feasible_train_split) : {np.mean(Feasible_train_split)}')\n",
    "# print(f'np.median(Feasible_train_split) : {np.median(Feasible_train_split)}')\n",
    "\n",
    "Xcal_split = eval(\"X_\" + dataset)[cal_inds_split]\n",
    "ycal_split = Y_all[cal_inds_split]\n",
    "Feasible_cal_split = Feasible_all[cal_inds_split]\n",
    "# print(f'np.mean(Feasible_cal_split) : {np.mean(Feasible_cal_split)}')\n",
    "# print(f'np.median(Feasible_cal_split) : {np.median(Feasible_cal_split)}')\n",
    "\n",
    "source_risk = np.mean(np.concatenate((Feasible_train_split, Feasible_cal_split)))\n",
    "print(f\"source risk : {1 - source_risk}\")\n",
    "\n",
    "plt.hist(ycal_split, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CB_color_cycle = [\n",
    "    \"#ff7f00\",\n",
    "    \"#4daf4a\",\n",
    "    \"#377eb8\",\n",
    "    \"#e41a1c\",\n",
    "    \"#984ea3\",\n",
    "    \"#f781bf\",\n",
    "    \"#999999\",\n",
    "    \"#dede00\",\n",
    "    \"#a65628\",\n",
    "]\n",
    "\n",
    "prob_bound_inf_str = \"1.0\"  ## {prob_bound_inf_str = '0.0' : Bounded query function (Appendix C), prob_bound_inf_str = '1.0' : Unbounded query function (Figure 3 main paper)}\n",
    "pca_bias_str_small = \"3.0\"\n",
    "pca_bias_str_big = \"3.0\"\n",
    "\n",
    "plt.rc(\"axes.spines\", top=False, right=False)\n",
    "# avoid Type 3 fonts\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "fig_h_dim = 4\n",
    "risk_control = \"Y\"\n",
    "\n",
    "pc_alpha = 0.5\n",
    "pc_alphas_dict = {\n",
    "    \"airfoil\": 0.2,\n",
    "    \"communities\": 0.2,\n",
    "    \"meps\": 0.2,\n",
    "    \"blog\": 0.2,\n",
    "    \"robot_arm\": 0.2,\n",
    "}\n",
    "\n",
    "# for i_data, dataset in enumerate(['airfoil', 'communities', 'meps', 'blog']):\n",
    "for i_data, dataset in enumerate([\"robot_arm\"]):  # , 'communities', 'meps', 'blog'\n",
    "    # for i_data, dataset in enumerate(['airfoil', 'communities']):\n",
    "\n",
    "    # for i_data, dataset in enumerate(['airfoil', 'meps', 'blog']): #, 'communities', 'meps', 'blog'\n",
    "\n",
    "    if dataset == \"airfoil\":\n",
    "        data_no_rc = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_airfoil_GP_nInitial80_steps100_nseed200_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling3.0_aciStepSize0.005_probBoundInf1.0_rcN_aciRCN_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "        data_rc = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_airfoil_GP_nInitial80_steps100_nseed200_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling3.0_aciStepSize0.5_probBoundInf1.0_rcY_aciRCN_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "        data_aci = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_airfoil_GP_nInitial80_steps100_nseed200_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling3.0_aciStepSize0.5_probBoundInf1.0_rcY_aciRCY_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "\n",
    "    elif dataset == \"communities\":\n",
    "        data_no_rc = pd.read_csv(\n",
    "            \"./results/2026-01-19_ALExpts_communities_GP_nInitial80_steps70_nseed200_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling8.0_aciStepSize0.005_probBoundInf1.0_rcN_aciRCN_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "        data_rc = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_communities_GP_nInitial80_steps100_nseed200_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling8.0_aciStepSize0.005_probBoundInf1.0_rcY_aciRCN_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "        data_aci = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_communities_GP_nInitial80_steps100_nseed200_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling8.0_aciStepSize0.5_probBoundInf1.0_rcY_aciRCY_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "\n",
    "    elif dataset == \"meps\":\n",
    "        data_no_rc = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_meps_GP_nInitial80_steps100_nseed10_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling8.0_aciStepSize0.005_probBoundInf1.0_rcN_aciRCN_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "        data_rc = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_meps_GP_nInitial80_steps100_nseed10_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling8.0_aciStepSize0.005_probBoundInf1.0_rcY_aciRCN_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "        data_aci = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_meps_GP_nInitial80_steps100_nseed10_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling8.0_aciStepSize0.5_probBoundInf1.0_rcY_aciRCY_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "\n",
    "    elif dataset == \"blog\":\n",
    "        data = pd.read_csv(\n",
    "            \"./results/2026-01-19_ALExpts_communities_GP_nInitial80_steps70_nseed1_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling8.0_aciStepSize0.005_probBoundInf1.0_rcN_aciRCN_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "\n",
    "    elif dataset == \"robot_arm\":\n",
    "        data_no_rc = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_robot_arm_GP_nInitial80_steps100_nseed200_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling8.0_aciStepSize0.5_probBoundInf1.0_rcN_aciRCN_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "        data_rc = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_robot_arm_GP_nInitial80_steps100_nseed200_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling8.0_aciStepSize0.5_probBoundInf1.0_rcY_aciRCN_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "        data_aci = pd.read_csv(\n",
    "            \"./results/2026-01-20_ALExpts_robot_arm_GP_nInitial80_steps100_nseed200_lmbda10.0_wDepths1_propTrainInit0.8_addTrainProb0.5_noise0.05_pcaExpSampling8.0_aciStepSize0.5_probBoundInf1.0_rcY_aciRCY_PCalpha0.2_cVSinitY.csv\"\n",
    "        )\n",
    "\n",
    "    data_dict = {\"no_rc\": data_no_rc, \"rc\": data_rc, \"aci\": data_aci}\n",
    "    data_list = [data_no_rc, data_rc, data_aci]\n",
    "\n",
    "    step_adjustments = [1]\n",
    "    wsplit_methods = [\"wsplit_\" + str(i) for i in step_adjustments]\n",
    "\n",
    "    method_names = np.concatenate(\n",
    "        [[\"split\"], wsplit_methods, [\"aci\", \"wsplit_mixture\"]]\n",
    "    )  # 'wsplit_2', 'wsplit_4', 'wsplit_5'\n",
    "    method_names_citations = [\n",
    "        \"Exchangeable Split CP (Papadopoulos 2008)\",\n",
    "        \"1-step FCS Split CP (Tibshirani et al., 2019 & Fannjiang et al., 2022)\",\n",
    "        \"2-step FCS Split CP (Prinster et al., 2024)\",\n",
    "        \"3-step FCS Split CP (Prinster et al., 2024)\",\n",
    "        \"ACI (Gibbs & Candes, 2021)\",\n",
    "        \"MixtureWeights (proposed)\",\n",
    "    ]  #'2-step FCS Split CP (proposed)','4-step FCS Split CP (proposed)', '5-step FCS Split CP (proposed)'\n",
    "\n",
    "    # data_all = data\n",
    "\n",
    "    # flur_color = 'red'\n",
    "    # muh_name = 'NN'\n",
    "    # ntrain = 192 ## 96, 192 ##\n",
    "    # K_str = '16'\n",
    "    # metric = 'coverage'\n",
    "    n_seeds = min([len(set(data[\"seed\"])) for data in data_list])\n",
    "    print(n_seeds)\n",
    "    n_test = 1\n",
    "    # lmbdas = [0, 1, 2, 3]\n",
    "\n",
    "    wid_q = 0.25\n",
    "    wid_e_color = \"gray\"\n",
    "    plot_legend = True\n",
    "    n_steps = 100\n",
    "\n",
    "    markersize = 10\n",
    "    linewidth = 3\n",
    "    capsize = 3\n",
    "    elinewidth = 2\n",
    "\n",
    "    transparency = 0.7\n",
    "    linestyle_wid = \"--\"\n",
    "    linestyle_fit = \"-.\"\n",
    "    y_ax_label_size = 18\n",
    "    x_ax_label_size = 18\n",
    "\n",
    "    tick_sizes = 20\n",
    "    suptitle_size = 30\n",
    "\n",
    "    BLUE = \"#2166ac\"  # β̂ vertical line\n",
    "    TEAL = \"#5ab4ac\"  # Calibration data (complements blue/red)\n",
    "    RED = \"#d73027\"\n",
    "\n",
    "    colors_dict = {\"no_rc\": RED, \"rc\": BLUE, \"aci\": \"C8\"}\n",
    "    markers_dict = {\"no_rc\": \"X\", \"rc\": \"o\", \"aci\": \"v\"}\n",
    "\n",
    "    ## Feasible set annotations\n",
    "    feasible_no_rc = (\n",
    "        data_dict[\"no_rc\"][data_dict[\"no_rc\"][\"method\"] == \"wsplit_mixture\"]\n",
    "        .groupby([\"step\"])[\"Feasible\"]\n",
    "        .mean()\n",
    "    )\n",
    "    feasible_no_rc_stderr = np.array(\n",
    "        data_dict[\"no_rc\"][data_dict[\"no_rc\"][\"method\"] == \"wsplit_mixture\"][\n",
    "            [\"Feasible\", \"step\"]\n",
    "        ]\n",
    "        .groupby([\"step\"])\n",
    "        .std()\n",
    "        / np.sqrt(n_seeds)\n",
    "    ).T[0]\n",
    "\n",
    "    feasible_rc = (\n",
    "        data_dict[\"rc\"][data_dict[\"rc\"][\"method\"] == \"wsplit_mixture\"]\n",
    "        .groupby([\"step\"])[\"Feasible\"]\n",
    "        .mean()\n",
    "    )\n",
    "    feasible_rc_stderr = np.array(\n",
    "        data_dict[\"rc\"][data_dict[\"rc\"][\"method\"] == \"wsplit_mixture\"][\n",
    "            [\"Feasible\", \"step\"]\n",
    "        ]\n",
    "        .groupby([\"step\"])\n",
    "        .std()\n",
    "        / np.sqrt(n_seeds)\n",
    "    ).T[0]\n",
    "\n",
    "    feasible_aci = (\n",
    "        data_dict[\"aci\"][data_dict[\"aci\"][\"method\"] == \"wsplit_mixture\"]\n",
    "        .groupby([\"step\"])[\"Feasible\"]\n",
    "        .mean()\n",
    "    )\n",
    "    feasible_aci_stderr = np.array(\n",
    "        data_dict[\"aci\"][data_dict[\"aci\"][\"method\"] == \"wsplit_mixture\"][\n",
    "            [\"Feasible\", \"step\"]\n",
    "        ]\n",
    "        .groupby([\"step\"])\n",
    "        .std()\n",
    "        / np.sqrt(n_seeds)\n",
    "    ).T[0]\n",
    "\n",
    "    feasible_dict = {\"no_rc\": feasible_no_rc, \"rc\": feasible_rc, \"aci\": feasible_aci}\n",
    "    feasible_stderr_dict = {\n",
    "        \"no_rc\": feasible_no_rc_stderr,\n",
    "        \"rc\": feasible_rc_stderr,\n",
    "        \"aci\": feasible_aci_stderr,\n",
    "    }\n",
    "\n",
    "    ## Compute MSE\n",
    "    MSE_no_rc = (\n",
    "        data_dict[\"no_rc\"][data_dict[\"no_rc\"][\"method\"] == \"split\"]\n",
    "        .groupby([\"step\"])[\"MSE\"]\n",
    "        .mean()\n",
    "    )\n",
    "    MSE_no_rc_stderr = np.array(\n",
    "        data_dict[\"no_rc\"][data_dict[\"no_rc\"][\"method\"] == \"split\"][[\"MSE\", \"step\"]]\n",
    "        .groupby([\"step\"])\n",
    "        .std()\n",
    "        / np.sqrt(n_seeds)\n",
    "    ).T[0]\n",
    "\n",
    "    MSE_rc = (\n",
    "        data_dict[\"rc\"][data_dict[\"rc\"][\"method\"] == \"split\"]\n",
    "        .groupby([\"step\"])[\"MSE\"]\n",
    "        .mean()\n",
    "    )\n",
    "    MSE_rc_stderr = np.array(\n",
    "        data_dict[\"rc\"][data_dict[\"rc\"][\"method\"] == \"split\"][[\"MSE\", \"step\"]]\n",
    "        .groupby([\"step\"])\n",
    "        .std()\n",
    "        / np.sqrt(n_seeds)\n",
    "    ).T[0]\n",
    "\n",
    "    MSE_aci = (\n",
    "        data_dict[\"aci\"][data_dict[\"aci\"][\"method\"] == \"split\"]\n",
    "        .groupby([\"step\"])[\"MSE\"]\n",
    "        .mean()\n",
    "    )\n",
    "    MSE_aci_stderr = np.array(\n",
    "        data_dict[\"aci\"][data_dict[\"aci\"][\"method\"] == \"split\"][[\"MSE\", \"step\"]]\n",
    "        .groupby([\"step\"])\n",
    "        .std()\n",
    "        / np.sqrt(n_seeds)\n",
    "    ).T[0]\n",
    "\n",
    "    MSE_dict = {\"no_rc\": MSE_no_rc, \"rc\": MSE_rc, \"aci\": MSE_aci}\n",
    "    MSE_stderr_dict = {\n",
    "        \"no_rc\": MSE_no_rc_stderr,\n",
    "        \"rc\": MSE_rc_stderr,\n",
    "        \"aci\": MSE_aci_stderr,\n",
    "    }\n",
    "\n",
    "    methods = [\"aci\", \"no_rc\", \"rc\"]\n",
    "    method_names_dict = {\n",
    "        \"no_rc\": \"Uncontrolled\",\n",
    "        \"rc\": \"Conformal Policy Control (proposed)\",\n",
    "        \"aci\": \"Conformal Controller (Lekeufack, et al. 2024)\",\n",
    "    }\n",
    "\n",
    "    ## Plot MSE\n",
    "    fig3, ax3 = plt.subplots(figsize=(8, fig_h_dim))\n",
    "    fig3.tight_layout()\n",
    "\n",
    "    ##\n",
    "    for m_i, method in enumerate(methods):\n",
    "        ax3.fill_between(\n",
    "            range(1, n_steps + 1),\n",
    "            MSE_dict[method][0:n_steps] - MSE_stderr_dict[method][0:n_steps],\n",
    "            MSE_dict[method][0:n_steps] + MSE_stderr_dict[method][0:n_steps],\n",
    "            alpha=transparency,\n",
    "            color=colors_dict[method],\n",
    "            zorder=m_i,\n",
    "        )\n",
    "        ax3.plot(\n",
    "            range(1, n_steps + 1),\n",
    "            MSE_dict[method][0:n_steps],\n",
    "            marker=markers_dict[method],\n",
    "            label=method_names_dict[method],\n",
    "            linewidth=linewidth,\n",
    "            alpha=transparency,\n",
    "            markersize=markersize,\n",
    "            color=colors_dict[method],\n",
    "            zorder=m_i,\n",
    "        )\n",
    "\n",
    "    # ax3.errorbar(range(1, n_steps+1), split_MSE[0:n_steps], marker='s', yerr = split_MSE_stderr[0:n_steps], ecolor = CB_color_cycle[0], label = 'split', linewidth=linewidth, alpha =transparency, markersize=markersize, color=CB_color_cycle[0], capsize=capsize,elinewidth=elinewidth)\n",
    "    # ax3.errorbar(range(1, n_steps+1), split_MSE[0:n_steps], marker='s', yerr = split_MSE_stderr[0:n_steps], ecolor = CB_color_cycle[0], label = 'split', linewidth=linewidth, alpha =transparency, markersize=markersize, color=CB_color_cycle[0], capsize=capsize,elinewidth=elinewidth)\n",
    "    # ax3.errorbar(range(1, n_steps+1), split_MSE[0:n_steps], marker='s', yerr = split_MSE_stderr[0:n_steps], ecolor = CB_color_cycle[0], label = 'split', linewidth=linewidth, alpha =transparency, markersize=markersize, color=CB_color_cycle[0], capsize=capsize,elinewidth=elinewidth)\n",
    "\n",
    "    ax3.set_ylabel(r\"Holdout Test Set MSE [$\\leftarrow$]\", fontsize=y_ax_label_size)\n",
    "    ax3.set_xlabel(\"Number of Active Learning Steps $t$\", fontsize=x_ax_label_size)\n",
    "    ax3.tick_params(axis=\"both\", labelsize=tick_sizes)\n",
    "    ax3.set_xticks(np.arange(0, n_steps + 1, 10.0))\n",
    "    # if (dataset == 'airfoil'):\n",
    "    #     ax3.set_yticks(np.arange(32, 37, 1))\n",
    "    # ax3.grid()\n",
    "    # ax3.set_ylim([32,36])\n",
    "\n",
    "    if prob_bound_inf_str != \"1.0\":\n",
    "        fig3.savefig(\n",
    "            f\"./results_figures/SplitCPActiveLearning_{dataset}_MSE.pdf\",\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "        )\n",
    "    else:\n",
    "        fig3.savefig(\n",
    "            f\"./results_figures/SplitCPActiveLearning_{dataset}_MSE.pdf\",\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "        )\n",
    "\n",
    "    ## Plot Feasibility\n",
    "    fig7, ax7 = plt.subplots(figsize=(8, fig_h_dim))\n",
    "    fig7.tight_layout()\n",
    "    ax7.axhline(\n",
    "        y=pc_alphas_dict[dataset],\n",
    "        linestyle=\":\",\n",
    "        color=\"black\",\n",
    "        linewidth=1.5 * linewidth,\n",
    "        label=\"Target Risk Upper Bound\",\n",
    "    )\n",
    "\n",
    "    # feasible = data[data['method']=='wsplit_mixture'].groupby(['step'])['Feasible'].mean()\n",
    "    # feasible_stderr = np.array(data[data['method']=='wsplit_mixture'][['Feasible', 'step']].groupby(['step']).std() / np.sqrt(n_seeds)).T[0]\n",
    "\n",
    "    # ## Plotting mean coverage\n",
    "    # ax7.errorbar(range(1, n_steps+1), feasible[0:n_steps], marker='s', yerr = feasible_stderr[0:n_steps], ecolor = 'black', label = 'Feasible indicator', linewidth=linewidth, alpha =transparency, markersize=markersize, color='black', capsize=capsize,elinewidth=elinewidth)\n",
    "    for m_i, method in enumerate(methods):\n",
    "        ax7.fill_between(\n",
    "            range(1, n_steps + 1),\n",
    "            1\n",
    "            - feasible_dict[method][0:n_steps]\n",
    "            - feasible_stderr_dict[method][0:n_steps],\n",
    "            1\n",
    "            - feasible_dict[method][0:n_steps]\n",
    "            + feasible_stderr_dict[method][0:n_steps],\n",
    "            alpha=transparency,\n",
    "            color=colors_dict[method],\n",
    "            zorder=m_i,\n",
    "        )\n",
    "        ax7.plot(\n",
    "            range(1, n_steps + 1),\n",
    "            1 - feasible_dict[method][0:n_steps],\n",
    "            marker=markers_dict[method],\n",
    "            label=method_names_dict[method],\n",
    "            linewidth=linewidth,\n",
    "            alpha=transparency,\n",
    "            markersize=markersize,\n",
    "            color=colors_dict[method],\n",
    "            zorder=m_i,\n",
    "        )\n",
    "\n",
    "    # handles, labels = ax3.get_legend_handles_labels()\n",
    "\n",
    "    ax7.set_ylabel(\n",
    "        r\"Constraint Violation Rate [$\\leftarrow$]\", fontsize=y_ax_label_size\n",
    "    )\n",
    "    ax7.set_xlabel(\"Number of Active Learning Steps $t$\", fontsize=x_ax_label_size)\n",
    "    ax7.tick_params(axis=\"both\", labelsize=tick_sizes)\n",
    "    ax7.set_xticks(np.arange(0, n_steps + 1, 10.0))\n",
    "    ax7.set_ylim([0, 1])\n",
    "    # ax7.legend(fontsize=20)\n",
    "\n",
    "    fig7.savefig(\n",
    "        f\"./results_figures/SplitCPActiveLearning_{dataset}_infeasiblity.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "    )\n",
    "\n",
    "    handles, labels = ax7.get_legend_handles_labels()\n",
    "    leg = ax7.legend(\n",
    "        handles, labels, loc=[-0.25, 1.3], ncols=8, fontsize=14, reverse=True\n",
    "    )\n",
    "    leg.set_in_layout(False)\n",
    "    legend_extent = leg.get_tightbbox(fig7.canvas.get_renderer()).transformed(\n",
    "        fig7.dpi_scale_trans.inverted()\n",
    "    )\n",
    "    fig7.savefig(\"legend_ActiveLearningExpts.pdf\", bbox_inches=legend_extent, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "m = sys.float_info.min\n",
    "\n",
    "M = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "M[:, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(1000))\n",
    "a[::-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_safe_actions(\n",
    "    cal_infeasible_indicators,\n",
    "    cal_lik_numerator,\n",
    "    cal_lik_denominator,\n",
    "    prop_lik_numerator,\n",
    "    prop_lik_denominator,\n",
    "    n_target,\n",
    "):\n",
    "\n",
    "    ## Unnormalized cal weights\n",
    "    w_cal = cal_lik_numerator / cal_lik_denominator\n",
    "    sum_w_cal = np.sum(w_cal)\n",
    "\n",
    "    ## Unnormalized estimated prop weight\n",
    "    w_test = np.mean(prop_lik_numerator / prop_lik_denominator)\n",
    "\n",
    "    for n in range(n_target + 1)[::-1]:\n",
    "        w_test_curr = n * w_test\n",
    "\n",
    "        sum_w_cal_test = sum_w_cal + w_test_curr\n",
    "\n",
    "        w_cal_normalized = w_cal / sum_w_cal_test\n",
    "        w_test_curr_normalized = w_test_curr / sum_w_cal_test\n",
    "\n",
    "        if (\n",
    "            np.sum(w_cal_normalized[cal_infeasible_indicators]) + w_test_curr_normalized\n",
    "            <= cfg.conformal_policy_control.alpha\n",
    "        ):\n",
    "            return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# L = [[1, 2, 3], [4, 5, 6]]\n",
    "# M = np.array(L)\n",
    "# np.array(M)\n",
    "L = [1, 2, 3]\n",
    "# L[-1] = 4\n",
    "L[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# ACI step size ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "CB_color_cycle = [\n",
    "    \"#ff7f00\",\n",
    "    \"#4daf4a\",\n",
    "    \"#377eb8\",\n",
    "    \"#e41a1c\",\n",
    "    \"#984ea3\",\n",
    "    \"#f781bf\",\n",
    "    \"#999999\",\n",
    "    \"#dede00\",\n",
    "    \"#a65628\",\n",
    "]\n",
    "\n",
    "prob_bound_inf_str = \"0.0\"  ## {prob_bound_inf_str = '0.0' : Bounded query function (Appendix C), prob_bound_inf_str = '1.0' : Unbounded query function (Figure 3 main paper)}\n",
    "pca_bias_str_small = \"3.0\"\n",
    "pca_bias_str_big = \"3.0\"\n",
    "\n",
    "plt.rc(\"axes.spines\", top=False, right=False)\n",
    "# avoid Type 3 fonts\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "fig_h_dim = 5\n",
    "\n",
    "for i_h, hyperparam in enumerate([0.005, 0.025, 0.05]):\n",
    "    for i_data, dataset in enumerate([\"airfoil\"]):\n",
    "        print(dataset)\n",
    "\n",
    "        if dataset == \"airfoil\":\n",
    "            # data = pd.read_csv('./results/2024-03-28_ALExpts_v7_airfoil_GP_itrain80_steps100_nseed1000_iseed0_tilt10.0_wAdjs123_PIs_propTraini0.8_addTrainProb0.5_replaceTrue_noise0.05_BySeed_pcaExpSampling' + pca_bias_str_small + '_GPRnoise0.05_sigDotProd0.05_aciStepSize0.005_beta' + prob_bound_inf_str + '_funcB.csv')\n",
    "            data = pd.read_csv(\n",
    "                \"/home/drewprinster/cp-ai-agents_20240201/results/2024-03-28_ALExpts_v7_airfoil_GP_itrain80_steps25_nseed500_iseed0_tilt10.0_wAdjs123_PIs_propTraini0.8_addTrainProb0.5_replaceTrue_noise0.05_BySeed_pcaExpSampling3.0_GPRnoise0.05_sigDotProd0.05_aciStepSize\"\n",
    "                + str(hyperparam)\n",
    "                + \"_beta1.0_funcB.csv\"\n",
    "            )\n",
    "\n",
    "        elif dataset == \"communities\":\n",
    "            data = pd.read_csv(\n",
    "                \"/home/drewprinster/cp-ai-agents_20240201/results/2024-03-28_ALExpts_v7_communities_GP_itrain80_steps100_nseed1000_iseed0_tilt10.0_wAdjs123_PIs_propTraini0.8_addTrainProb0.5_replaceTrue_noise0.05_BySeed_pcaExpSampling\"\n",
    "                + pca_bias_str_small\n",
    "                + \"_GPRnoise0.05_sigDotProd0.05_aciStepSize0.005_beta\"\n",
    "                + prob_bound_inf_str\n",
    "                + \"_funcB.csv\"\n",
    "            )\n",
    "\n",
    "        elif dataset == \"meps\":\n",
    "            data = pd.read_csv(\n",
    "                \"/home/drewprinster/cp-ai-agents_20240201/results/2024-03-28_ALExpts_v7_meps_GP_itrain80_steps100_nseed1000_iseed0_tilt10.0_wAdjs123_PIs_propTraini0.8_addTrainProb0.5_replaceTrue_noise0.05_BySeed_pcaExpSampling\"\n",
    "                + pca_bias_str_big\n",
    "                + \"_GPRnoise0.05_sigDotProd0.05_aciStepSize0.005_beta\"\n",
    "                + prob_bound_inf_str\n",
    "                + \"_funcB.csv\"\n",
    "            )\n",
    "\n",
    "        elif dataset == \"blog\":\n",
    "            data = pd.read_csv(\n",
    "                \"/home/drewprinster/cp-ai-agents_20240201/results/2024-03-28_ALExpts_v7_blog_GP_itrain80_steps100_nseed1000_iseed0_tilt10.0_wAdjs123_PIs_propTraini0.8_addTrainProb0.5_replaceTrue_noise0.05_BySeed_pcaExpSampling\"\n",
    "                + pca_bias_str_big\n",
    "                + \"_GPRnoise0.05_sigDotProd0.05_aciStepSize0.005_beta\"\n",
    "                + prob_bound_inf_str\n",
    "                + \"_funcB.csv\"\n",
    "            )\n",
    "\n",
    "        data = data[data[\"seed\"] < 350]\n",
    "\n",
    "        step_adjustments = [1, 3]\n",
    "        wsplit_methods = [\"wsplit_\" + str(i) for i in step_adjustments]\n",
    "\n",
    "        method_names = np.concatenate(\n",
    "            [[\"split\"], wsplit_methods, [\"aci\"]]\n",
    "        )  # 'wsplit_2', 'wsplit_4', 'wsplit_5'\n",
    "        method_names_citations = [\n",
    "            \"Exchangeable Split CP (Papadopoulos 2008)\",\n",
    "            \"1-step FCS Split CP (Tibshirani et al., 2019 & Fannjiang et al., 2022)\",\n",
    "            \"2-step FCS Split CP (proposed)\",\n",
    "            \"3-step FCS Split CP (proposed)\",\n",
    "            \"ACI (Gibbs & Candes, 2021)\",\n",
    "        ]  #'2-step FCS Split CP (proposed)','4-step FCS Split CP (proposed)', '5-step FCS Split CP (proposed)'\n",
    "\n",
    "        data_all = data\n",
    "\n",
    "        print(max(data[\"seed\"]))\n",
    "\n",
    "        # flur_color = 'red'\n",
    "        # muh_name = 'NN'\n",
    "        # ntrain = 192 ## 96, 192 ##\n",
    "        # K_str = '16'\n",
    "        # metric = 'coverage'\n",
    "        n_seeds = len(set(data[\"seed\"]))\n",
    "        n_test = 1\n",
    "        # lmbdas = [0, 1, 2, 3]\n",
    "\n",
    "        wid_q = 0.25\n",
    "        wid_e_color = \"gray\"\n",
    "        plot_legend = False\n",
    "        n_steps = 25\n",
    "\n",
    "        markersize = 10\n",
    "        linewidth = 3\n",
    "        capsize = 3\n",
    "        elinewidth = 2\n",
    "\n",
    "        transparency = 0.7\n",
    "        linestyle_wid = \"--\"\n",
    "        linestyle_fit = \"-.\"\n",
    "        y_ax_label_size = 25\n",
    "        x_ax_label_size = 25\n",
    "\n",
    "        tick_sizes = 20\n",
    "        suptitle_size = 30\n",
    "\n",
    "        ## Compute mean coverage\n",
    "        split_cov = data[data[\"method\"] == \"split\"].groupby([\"step\"]).mean()[\"coverage\"]\n",
    "        split_cov_stderr = np.array(\n",
    "            data[data[\"method\"] == \"split\"][[\"coverage\", \"step\"]]\n",
    "            .groupby([\"step\"])\n",
    "            .std()\n",
    "            / np.sqrt(n_seeds)\n",
    "        ).T[0]\n",
    "\n",
    "        wsplit_cov_list = []\n",
    "        wsplit_cov_stderr_list = []\n",
    "        for i in range(min(step_adjustments), max(step_adjustments) + 1):\n",
    "            wsplit_cov_list.append(\n",
    "                data[data[\"method\"] == \"wsplit_\" + str(i)]\n",
    "                .groupby([\"step\"])\n",
    "                .mean()[\"coverage\"]\n",
    "            )\n",
    "            wsplit_cov_stderr_list.append(\n",
    "                np.array(\n",
    "                    data[data[\"method\"] == \"wsplit_\" + str(i)][[\"coverage\", \"step\"]]\n",
    "                    .groupby([\"step\"])\n",
    "                    .std()\n",
    "                    / np.sqrt(n_seeds)\n",
    "                ).T[0]\n",
    "            )\n",
    "\n",
    "        aci_cov = data[data[\"method\"] == \"aci\"].groupby([\"step\"]).mean()[\"coverage\"]\n",
    "        aci_cov_stderr = np.array(\n",
    "            data[data[\"method\"] == \"aci\"][[\"coverage\", \"step\"]].groupby([\"step\"]).std()\n",
    "            / np.sqrt(n_seeds)\n",
    "        ).T[0]\n",
    "\n",
    "        ## Compute median width\n",
    "        split_wid = data[data[\"method\"] == \"split\"].groupby([\"step\"]).median()[\"width\"]\n",
    "        split_wid_stderr_l = (\n",
    "            np.array(split_wid)\n",
    "            - np.array(\n",
    "                data_all[data_all[\"method\"] == \"split\"][[\"width\", \"step\"]]\n",
    "                .groupby([\"step\"])\n",
    "                .quantile(wid_q)\n",
    "            ).T[0]\n",
    "        )\n",
    "        split_wid_stderr_u = np.array(\n",
    "            data_all[data_all[\"method\"] == \"split\"][[\"width\", \"step\"]]\n",
    "            .groupby([\"step\"])\n",
    "            .quantile(1 - wid_q)\n",
    "        ).T[0] - np.array(split_wid)\n",
    "\n",
    "        wsplit_wid_list = []\n",
    "        wsplit_wid_stderr_l_list = []\n",
    "        wsplit_wid_stderr_u_list = []\n",
    "        for i in range(min(step_adjustments), max(step_adjustments) + 1):\n",
    "            wsplit_wid_list.append(\n",
    "                data[data[\"method\"] == \"wsplit_\" + str(i)]\n",
    "                .groupby([\"step\"])\n",
    "                .median()[\"width\"]\n",
    "            )\n",
    "            wsplit_wid_stderr_l_curr = (\n",
    "                np.array(wsplit_wid_list[-1])\n",
    "                - np.array(\n",
    "                    data_all[data_all[\"method\"] == \"wsplit_\" + str(i)][\n",
    "                        [\"width\", \"step\"]\n",
    "                    ]\n",
    "                    .groupby([\"step\"])\n",
    "                    .quantile(wid_q)\n",
    "                ).T[0]\n",
    "            )\n",
    "            wsplit_wid_stderr_l_curr = np.nan_to_num(\n",
    "                wsplit_wid_stderr_l_curr, nan=0.0, neginf=0.0\n",
    "            )\n",
    "            wsplit_wid_stderr_l_list.append(\n",
    "                wsplit_wid_stderr_l_curr\n",
    "            )  ## Aesthetic plotting adjustment, for when values are -infinite\n",
    "\n",
    "            wsplit_wid_stderr_u_curr = np.array(\n",
    "                data_all[data_all[\"method\"] == \"wsplit_\" + str(i)][[\"width\", \"step\"]]\n",
    "                .groupby([\"step\"])\n",
    "                .quantile(1 - wid_q)\n",
    "            ).T[0] - np.array(wsplit_wid_list[-1])\n",
    "            wsplit_wid_stderr_u_curr = np.nan_to_num(\n",
    "                wsplit_wid_stderr_u_curr, nan=60.0, posinf=60.0\n",
    "            )\n",
    "            wsplit_wid_stderr_u_list.append(\n",
    "                wsplit_wid_stderr_u_curr\n",
    "            )  ## Aesthetic plotting adjustment, for when values are infinite\n",
    "\n",
    "        aci_wid = data[data[\"method\"] == \"aci\"].groupby([\"step\"]).median()[\"width\"]\n",
    "        aci_wid_stderr_l = (\n",
    "            np.array(aci_wid)\n",
    "            - np.array(\n",
    "                data_all[data_all[\"method\"] == \"aci\"][[\"width\", \"step\"]]\n",
    "                .groupby([\"step\"])\n",
    "                .quantile(wid_q)\n",
    "            ).T[0]\n",
    "        )\n",
    "        aci_wid_stderr_l = np.nan_to_num(aci_wid_stderr_l, nan=0.0, neginf=0.0)\n",
    "        # aci_wid_stderr_l = np.where(aci_wid_stderr_l < 0, 0, aci_wid_stderr_l)\n",
    "        aci_wid_stderr_u = np.array(\n",
    "            data_all[data_all[\"method\"] == \"aci\"][[\"width\", \"step\"]]\n",
    "            .groupby([\"step\"])\n",
    "            .quantile(1 - wid_q)\n",
    "        ).T[0] - np.array(aci_wid)\n",
    "        aci_wid_stderr_u = np.nan_to_num(aci_wid_stderr_u, nan=60.0, neginf=60.0)\n",
    "\n",
    "        ## Compute MSE\n",
    "        split_MSE = data[data[\"method\"] == \"split\"].groupby([\"step\"]).mean()[\"MSE\"]\n",
    "        split_MSE_stderr = np.array(\n",
    "            data[data[\"method\"] == \"split\"][[\"MSE\", \"step\"]].groupby([\"step\"]).std()\n",
    "            / np.sqrt(n_seeds)\n",
    "        ).T[0]\n",
    "\n",
    "        wsplit_MSE_list = []\n",
    "        wsplit_MSE_stderr_list = []\n",
    "        for i in range(min(step_adjustments), max(step_adjustments) + 1):\n",
    "            wsplit_MSE_list.append(\n",
    "                data[data[\"method\"] == \"wsplit_\" + str(i)]\n",
    "                .groupby([\"step\"])\n",
    "                .mean()[\"MSE\"]\n",
    "            )\n",
    "            wsplit_MSE_stderr_list.append(\n",
    "                np.array(\n",
    "                    data[data[\"method\"] == \"wsplit_\" + str(i)][[\"MSE\", \"step\"]]\n",
    "                    .groupby([\"step\"])\n",
    "                    .std()\n",
    "                    / np.sqrt(n_seeds)\n",
    "                ).T[0]\n",
    "            )\n",
    "\n",
    "        aci_MSE = data[data[\"method\"] == \"aci\"].groupby([\"step\"]).mean()[\"MSE\"]\n",
    "        aci_MSE_stderr = np.array(\n",
    "            data[data[\"method\"] == \"aci\"][[\"MSE\", \"step\"]].groupby([\"step\"]).std()\n",
    "            / np.sqrt(n_seeds)\n",
    "        ).T[0]\n",
    "\n",
    "        ## Relative query function bound\n",
    "        prop_B = data[data[\"method\"] == \"wsplit_1\"].groupby([\"step\"]).mean()[\"prop_B\"]\n",
    "        prop_B_stderr = np.array(\n",
    "            data[data[\"method\"] == \"wsplit_1\"][[\"prop_B\", \"step\"]]\n",
    "            .groupby([\"step\"])\n",
    "            .std()\n",
    "            / np.sqrt(n_seeds)\n",
    "        ).T[0]\n",
    "\n",
    "        ### alpha_aci and prop_B\n",
    "        aci_level = (\n",
    "            1 - data[data[\"method\"] == \"aci\"].groupby([\"step\"]).mean()[\"alpha_aci\"]\n",
    "        )\n",
    "\n",
    "        # print(np.array(data[data['method']=='aci'][['alpha_aci', 'step']].groupby(['step'])))\n",
    "        aci_level_stderr = (\n",
    "            np.array(\n",
    "                1\n",
    "                - data[data[\"method\"] == \"aci\"][[\"alpha_aci\", \"step\"]]\n",
    "                .groupby([\"step\"])\n",
    "                .std()\n",
    "            )\n",
    "            / np.sqrt(n_seeds)\n",
    "        ).T[0]\n",
    "\n",
    "        ## Plotting\n",
    "\n",
    "        ## Plot coverage\n",
    "\n",
    "        fig1, ax1 = plt.subplots(figsize=(8, fig_h_dim))\n",
    "        fig1.tight_layout()\n",
    "\n",
    "        ## Plotting mean coverage\n",
    "        ax1.errorbar(\n",
    "            range(1, n_steps + 1),\n",
    "            split_cov[0:n_steps],\n",
    "            marker=\"s\",\n",
    "            yerr=split_cov_stderr[0:n_steps],\n",
    "            ecolor=CB_color_cycle[0],\n",
    "            label=\"Exchangeable Split CP (Papadopoulos 2008)\",\n",
    "            linewidth=linewidth,\n",
    "            alpha=transparency,\n",
    "            markersize=markersize,\n",
    "            color=CB_color_cycle[0],\n",
    "            capsize=capsize,\n",
    "            elinewidth=elinewidth,\n",
    "        )\n",
    "\n",
    "        ax1.errorbar(\n",
    "            range(1, n_steps + 1),\n",
    "            aci_cov[0:n_steps],\n",
    "            marker=\"s\",\n",
    "            yerr=aci_cov_stderr[0:n_steps],\n",
    "            ecolor=CB_color_cycle[6],\n",
    "            label=\"ACI (Gibbs & Candes, 2021)\",\n",
    "            linewidth=linewidth,\n",
    "            alpha=transparency,\n",
    "            markersize=markersize,\n",
    "            color=CB_color_cycle[6],\n",
    "            capsize=capsize,\n",
    "            elinewidth=elinewidth,\n",
    "        )\n",
    "\n",
    "        for i in step_adjustments:\n",
    "            #     print(i)\n",
    "            if i == 1:\n",
    "                ax1.errorbar(\n",
    "                    range(1, n_steps + 1),\n",
    "                    wsplit_cov_list[i - 1][0:n_steps],\n",
    "                    marker=\"v\",\n",
    "                    yerr=wsplit_cov_stderr_list[i - 1][0:n_steps],\n",
    "                    ecolor=CB_color_cycle[i],\n",
    "                    label=method_names_citations[i],\n",
    "                    linewidth=linewidth,\n",
    "                    alpha=transparency,\n",
    "                    markersize=markersize,\n",
    "                    color=CB_color_cycle[i],\n",
    "                    capsize=capsize,\n",
    "                    elinewidth=elinewidth,\n",
    "                )\n",
    "            else:\n",
    "                ax1.errorbar(\n",
    "                    range(1, n_steps + 1),\n",
    "                    wsplit_cov_list[i - 1][0:n_steps],\n",
    "                    marker=\"o\",\n",
    "                    yerr=wsplit_cov_stderr_list[i - 1][0:n_steps],\n",
    "                    ecolor=CB_color_cycle[i],\n",
    "                    label=method_names_citations[i],\n",
    "                    linewidth=linewidth,\n",
    "                    alpha=transparency,\n",
    "                    markersize=markersize,\n",
    "                    color=CB_color_cycle[i],\n",
    "                    capsize=capsize,\n",
    "                    elinewidth=elinewidth,\n",
    "                )\n",
    "\n",
    "        ax1.axhline(\n",
    "            y=0.9,\n",
    "            linestyle=\":\",\n",
    "            color=\"black\",\n",
    "            linewidth=1.5 * linewidth,\n",
    "            label=\"Target coverage\",\n",
    "        )\n",
    "\n",
    "        handles, labels = ax1.get_legend_handles_labels()\n",
    "\n",
    "        ax1.set_ylabel(\"Mean coverage\", fontsize=y_ax_label_size)\n",
    "        ax1.set_xlabel(\"Number of active learning steps $t$\", fontsize=x_ax_label_size)\n",
    "        ax1.tick_params(axis=\"both\", labelsize=tick_sizes)\n",
    "        ax1.set_xticks(np.arange(0, n_steps + 1, 5.0))\n",
    "\n",
    "        if dataset == \"airfoil\":\n",
    "            ax1.set_ylim([0.78, 1.0000001])\n",
    "        elif dataset == \"communities\":\n",
    "            ax1.set_ylim([0.52, 1.0000001])\n",
    "        elif dataset == \"meps\":\n",
    "            ax1.set_ylim([0.52, 1.0000001])\n",
    "        elif dataset == \"blog\":\n",
    "            ax1.set_ylim([0.64, 1.0000001])\n",
    "\n",
    "        ax1.set_yticks(np.arange(0.5, 1.0000001, 0.1))\n",
    "        ax1.grid()\n",
    "\n",
    "        if prob_bound_inf_str != \"1.0\":\n",
    "            fig1.savefig(\n",
    "                \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_\"\n",
    "                + dataset\n",
    "                + \"_aciStepSize\"\n",
    "                + str(hyperparam)\n",
    "                + \"_coverage.pdf\",\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "        else:\n",
    "            fig1.savefig(\n",
    "                \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_\"\n",
    "                + dataset\n",
    "                + \"_aciStepSize\"\n",
    "                + str(hyperparam)\n",
    "                + \"_coverage.pdf\",\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "\n",
    "        ## Plot width\n",
    "        fig2, ax2 = plt.subplots(figsize=(8, fig_h_dim))\n",
    "        fig2.tight_layout()\n",
    "\n",
    "        ax2.errorbar(\n",
    "            range(1, n_steps + 1),\n",
    "            split_wid[0:n_steps],\n",
    "            marker=\"s\",\n",
    "            yerr=np.vstack(\n",
    "                (split_wid_stderr_l[0:n_steps], split_wid_stderr_u[0:n_steps])\n",
    "            ),\n",
    "            ecolor=CB_color_cycle[0],\n",
    "            label=\"split\",\n",
    "            linewidth=linewidth,\n",
    "            alpha=transparency,\n",
    "            markersize=markersize,\n",
    "            color=CB_color_cycle[0],\n",
    "            capsize=capsize,\n",
    "            elinewidth=elinewidth,\n",
    "        )\n",
    "        ax2.errorbar(\n",
    "            range(1, n_steps + 1),\n",
    "            aci_wid[0:n_steps],\n",
    "            marker=\"s\",\n",
    "            yerr=np.vstack((aci_wid_stderr_l[0:n_steps], aci_wid_stderr_u[0:n_steps])),\n",
    "            ecolor=CB_color_cycle[6],\n",
    "            label=\"aci\",\n",
    "            linewidth=linewidth,\n",
    "            alpha=transparency,\n",
    "            markersize=markersize,\n",
    "            color=CB_color_cycle[6],\n",
    "            capsize=capsize,\n",
    "            elinewidth=elinewidth,\n",
    "        )\n",
    "\n",
    "        for i in step_adjustments:\n",
    "            if i == 1:\n",
    "                ax2.errorbar(\n",
    "                    range(1, n_steps + 1),\n",
    "                    wsplit_wid_list[i - 1][0:n_steps],\n",
    "                    marker=\"v\",\n",
    "                    yerr=np.vstack(\n",
    "                        (\n",
    "                            wsplit_wid_stderr_l_list[i - 1][0:n_steps],\n",
    "                            wsplit_wid_stderr_u_list[i - 1][0:n_steps],\n",
    "                        )\n",
    "                    ),\n",
    "                    ecolor=CB_color_cycle[i],\n",
    "                    label=method_names_citations[i],\n",
    "                    linewidth=linewidth,\n",
    "                    alpha=transparency,\n",
    "                    markersize=markersize,\n",
    "                    color=CB_color_cycle[i],\n",
    "                    capsize=capsize,\n",
    "                    elinewidth=elinewidth,\n",
    "                )\n",
    "            else:\n",
    "                ax2.errorbar(\n",
    "                    range(1, n_steps + 1),\n",
    "                    wsplit_wid_list[i - 1][0:n_steps],\n",
    "                    marker=\"o\",\n",
    "                    yerr=np.vstack(\n",
    "                        (\n",
    "                            wsplit_wid_stderr_l_list[i - 1][0:n_steps],\n",
    "                            wsplit_wid_stderr_u_list[i - 1][0:n_steps],\n",
    "                        )\n",
    "                    ),\n",
    "                    ecolor=CB_color_cycle[i],\n",
    "                    label=method_names_citations[i],\n",
    "                    linewidth=linewidth,\n",
    "                    alpha=transparency,\n",
    "                    markersize=markersize,\n",
    "                    color=CB_color_cycle[i],\n",
    "                    capsize=capsize,\n",
    "                    elinewidth=elinewidth,\n",
    "                )\n",
    "\n",
    "        ax2.set_ylabel(\"Median interval width\", fontsize=y_ax_label_size)\n",
    "        ax2.set_xlabel(\"Number of active learning steps $t$\", fontsize=x_ax_label_size)\n",
    "        if dataset == \"airfoil\":\n",
    "            # ax2.set_title('Airfoil dataset', y=1.025, fontsize=suptitle_size)\n",
    "            ax2.set_ylim([0, 39])\n",
    "        elif dataset == \"communities\":\n",
    "            # ax2.set_title('Communities dataset', y=1.025, fontsize=suptitle_size)\n",
    "            ax2.set_ylim([0, 4.5])\n",
    "        elif dataset == \"meps\":\n",
    "            # ax2.set_title('MEPS dataset', y=1.025, fontsize=suptitle_size)\n",
    "            ax2.set_ylim([0, 15])\n",
    "        elif dataset == \"blog\":\n",
    "            # ax2.set_title('Blog dataset', y=1.025, fontsize=suptitle_size)\n",
    "            ax2.set_ylim([0, 155])\n",
    "\n",
    "        # ax2.axhline(y = 0.9, linestyle = ':', color = 'black', linewidth=2)\n",
    "        ax2.tick_params(axis=\"both\", labelsize=tick_sizes)\n",
    "        ax2.set_xticks(np.arange(0, n_steps + 1, 5.0))\n",
    "        ax2.grid()\n",
    "\n",
    "        if prob_bound_inf_str != \"1.0\":\n",
    "            fig2.savefig(\n",
    "                \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_\"\n",
    "                + dataset\n",
    "                + \"_aciStepSize\"\n",
    "                + str(hyperparam)\n",
    "                + \"_width.pdf\",\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "        else:\n",
    "            fig2.savefig(\n",
    "                \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_\"\n",
    "                + dataset\n",
    "                + \"_aciStepSize\"\n",
    "                + str(hyperparam)\n",
    "                + \"_width.pdf\",\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "\n",
    "        ## Plot MSE\n",
    "        fig3, ax3 = plt.subplots(figsize=(8, fig_h_dim))\n",
    "        fig3.tight_layout()\n",
    "\n",
    "        ax3.errorbar(\n",
    "            range(1, n_steps + 1),\n",
    "            split_MSE[0:n_steps],\n",
    "            marker=\"s\",\n",
    "            yerr=split_MSE_stderr[0:n_steps],\n",
    "            ecolor=CB_color_cycle[0],\n",
    "            label=\"split\",\n",
    "            linewidth=linewidth,\n",
    "            alpha=transparency,\n",
    "            markersize=markersize,\n",
    "            color=CB_color_cycle[0],\n",
    "            capsize=capsize,\n",
    "            elinewidth=elinewidth,\n",
    "        )\n",
    "        ax3.errorbar(\n",
    "            range(1, n_steps + 1),\n",
    "            aci_MSE[0:n_steps],\n",
    "            marker=\"s\",\n",
    "            yerr=aci_MSE_stderr[0:n_steps],\n",
    "            ecolor=CB_color_cycle[6],\n",
    "            label=\"aci\",\n",
    "            linewidth=linewidth,\n",
    "            alpha=transparency,\n",
    "            markersize=markersize,\n",
    "            color=CB_color_cycle[6],\n",
    "            capsize=capsize,\n",
    "            elinewidth=elinewidth,\n",
    "        )\n",
    "\n",
    "        for i in step_adjustments:\n",
    "            if i == 1:\n",
    "                ax3.errorbar(\n",
    "                    range(1, n_steps + 1),\n",
    "                    wsplit_MSE_list[i - 1][0:n_steps],\n",
    "                    marker=\"v\",\n",
    "                    yerr=wsplit_MSE_stderr_list[i - 1][0:n_steps],\n",
    "                    ecolor=CB_color_cycle[i],\n",
    "                    label=method_names_citations[i],\n",
    "                    linewidth=linewidth,\n",
    "                    alpha=transparency,\n",
    "                    markersize=markersize,\n",
    "                    color=CB_color_cycle[i],\n",
    "                    capsize=capsize,\n",
    "                    elinewidth=elinewidth,\n",
    "                )\n",
    "            else:\n",
    "                ax3.errorbar(\n",
    "                    range(1, n_steps + 1),\n",
    "                    wsplit_MSE_list[i - 1][0:n_steps],\n",
    "                    marker=\"o\",\n",
    "                    yerr=wsplit_MSE_stderr_list[i - 1][0:n_steps],\n",
    "                    ecolor=CB_color_cycle[i],\n",
    "                    label=method_names_citations[i],\n",
    "                    linewidth=linewidth,\n",
    "                    alpha=transparency,\n",
    "                    markersize=markersize,\n",
    "                    color=CB_color_cycle[i],\n",
    "                    capsize=capsize,\n",
    "                    elinewidth=elinewidth,\n",
    "                )\n",
    "\n",
    "        ax3.set_ylabel(\"Holdout test set MSE\", fontsize=y_ax_label_size)\n",
    "        ax3.set_xlabel(\"Number of active learning steps $t$\", fontsize=x_ax_label_size)\n",
    "        ax3.tick_params(axis=\"both\", labelsize=tick_sizes)\n",
    "        ax3.set_xticks(np.arange(0, n_steps + 1, 5.0))\n",
    "        if dataset == \"airfoil\":\n",
    "            ax3.set_yticks(np.arange(33, 37, 1))\n",
    "        ax3.grid()\n",
    "\n",
    "        if prob_bound_inf_str != \"1.0\":\n",
    "            fig3.savefig(\n",
    "                \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_\"\n",
    "                + dataset\n",
    "                + \"_aciStepSize\"\n",
    "                + str(hyperparam)\n",
    "                + \"_MSE.pdf\",\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "        else:\n",
    "            fig3.savefig(\n",
    "                \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_\"\n",
    "                + dataset\n",
    "                + \"_aciStepSize\"\n",
    "                + str(hyperparam)\n",
    "                + \"_MSE.pdf\",\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "\n",
    "        ## Plot relative bound\n",
    "        fig4, ax4 = plt.subplots(figsize=(8, fig_h_dim))\n",
    "        fig4.tight_layout()\n",
    "\n",
    "        # ### Prop B\n",
    "        # if (prob_bound_inf_str != '1.0'):\n",
    "\n",
    "        # ax4.errorbar(range(1, n_steps+1), prop_B[0:n_steps], marker='s', yerr = prop_B_stderr[0:n_steps], ecolor = 'black', label = 'B / max(w_{n+t}(x))', linewidth=linewidth, alpha =transparency, markersize=markersize, color='black', capsize=capsize,elinewidth=elinewidth)\n",
    "        # ax4.set_ylabel('Relative magnitude of B', fontsize=y_ax_label_size)\n",
    "        # ax4.set_xlabel('Number of active learning steps $t$', fontsize=x_ax_label_size)\n",
    "        # ax4.tick_params(axis='both', labelsize=tick_sizes)\n",
    "        # ax4.set_xticks(np.arange(0, n_steps+1, 5.0))\n",
    "        # ax4.set_title('Relative magnitude of \\n query function bound B', fontsize=y_ax_label_size+4)\n",
    "        # ax4.set_ylim(top=1.0)\n",
    "        ax4.errorbar(\n",
    "            range(1, n_steps + 1),\n",
    "            aci_level[0:n_steps],\n",
    "            marker=\"s\",\n",
    "            yerr=aci_level_stderr[0:n_steps],\n",
    "            ecolor=CB_color_cycle[6],\n",
    "            label=\"ACI quantile level $1- \" + chr(945) + \"_{aci}$\",\n",
    "            linewidth=linewidth,\n",
    "            alpha=transparency,\n",
    "            markersize=markersize,\n",
    "            color=CB_color_cycle[6],\n",
    "            capsize=capsize,\n",
    "            elinewidth=elinewidth,\n",
    "        )\n",
    "        ax4.set_ylabel(\"$1- \" + chr(945) + \"_{aci}$\", fontsize=y_ax_label_size)\n",
    "        ax4.set_xlabel(\"Number of active learning steps $t$\", fontsize=x_ax_label_size)\n",
    "        ax4.tick_params(axis=\"both\", labelsize=tick_sizes)\n",
    "        ax4.set_xticks(np.arange(0, n_steps + 1, 5.0))\n",
    "        ax4.set_title(\n",
    "            \"ACI quantile level $1- \" + chr(945) + \"_{aci}$\", fontsize=y_ax_label_size\n",
    "        )\n",
    "        ax4.set_ylim([0.8, 1.02])\n",
    "        ax4.grid()\n",
    "\n",
    "        fig4.savefig(\n",
    "            \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_\"\n",
    "            + dataset\n",
    "            + \"_aciStepSize\"\n",
    "            + str(hyperparam)\n",
    "            + \"_ACIlevel.pdf\",\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=200,\n",
    "        )\n",
    "\n",
    "        # else:\n",
    "        # fig4.savefig('/home/drewprinster/cp-ai-agents_20240201/results_figures/AblationSplitCPActiveLearning_unbounded_' + dataset + '_aciStepSize' + str(hyperparam) + '_propB.pdf',bbox_inches='tight', dpi=300)\n",
    "\n",
    "        ## Plot legend\n",
    "        fig5, ax5 = plt.subplots(figsize=(0, 0))\n",
    "\n",
    "        ax5.set_xticks([])\n",
    "        ax5.set_yticks([])\n",
    "\n",
    "        order = list(range(0, len(method_names) + 1))\n",
    "        ax5.legend(\n",
    "            [handles[idx] for idx in order],\n",
    "            [labels[idx] for idx in order],\n",
    "            loc=[-0.15, 1.3],\n",
    "            ncol=3,\n",
    "            fontsize=20,\n",
    "        )\n",
    "\n",
    "        if prob_bound_inf_str != \"1.0\":\n",
    "            fig5.savefig(\n",
    "                \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_legend.pdf\",\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "        else:\n",
    "            fig5.savefig(\n",
    "                \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_legend.pdf\",\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "\n",
    "        ## Plot title\n",
    "        fig6, ax6 = plt.subplots(figsize=(0, 0))\n",
    "\n",
    "        ax6.set_xticks([])\n",
    "        ax6.set_yticks([])\n",
    "\n",
    "        if prob_bound_inf_str != \"1.0\":\n",
    "            ax6.set_title(\n",
    "                \"ACI step size = \" + str(hyperparam), y=1.025, fontsize=suptitle_size\n",
    "            )\n",
    "            fig6.savefig(\n",
    "                \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_\"\n",
    "                + dataset\n",
    "                + \"_aciStepSize\"\n",
    "                + str(hyperparam)\n",
    "                + \"_title.pdf\",\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "        else:\n",
    "            ax6.set_title(\n",
    "                \"ACI step size = \" + str(hyperparam), y=1.025, fontsize=suptitle_size\n",
    "            )\n",
    "            fig6.savefig(\n",
    "                \"/home/drewprinster/conformal-mfcs/results_figures/AblationSplitCPActiveLearning_\"\n",
    "                + dataset\n",
    "                + \"_aciStepSize\"\n",
    "                + str(hyperparam)\n",
    "                + \"_title.pdf\",\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "constrained_AL",
   "language": "python",
   "name": "constrained_al"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
